---
layout: post
title: Social Network Analysis
---

Our last assignment, also the final assignment of the course, revolves around social network analysis. Our assignment was all about the relations of names in the first part of the assignment (i.e. the names mentioned in the same units (articles, obituaries, etc.)), and about the relations of toponyms in the second part of the assignment.
What we had to do in short:

1) collect first the names, then the toponyms in the 'Dispatch' and remove duplicates;
2) convert them into edges (we got a piece of code for that); I used a list to collect the names and then a dictionary to count the frequencies. (I actually got quite a lot of help for that).
3) after all the edges were collected, I counted their frequencies in a dictionary (edgesDic) with the updateDic function;
4) the result is then a table (a *.tsv file) with three columns: source, target, weight; there is a number of options to calculate the weight; I decided to use the frequency as weight for my sna table;

```
		import re, os

		source = ".//files"
		target = ".//res"

		#create a list and a dictionary to save the extracted information to
		edgesDic = {} # dictionary for edges
		edgesList = [] # list for names

		def updateDic(dic, key): # updating dictionary, we got this piece of code
			if key in dic:
				dic[key] += 1
			else:
				dic[key] = 1
			
		def taggedNames(unitText): # define function to collect tagged names in edgesList
			namesInUnit = [] #create list for names in unit
			for names in re.findall(r'<[pP]ersName[^<]+', unitText, flags=0):
				match = re.search(r'authname="([\w,]+)"', names)
				if match:
					name = match.group(1) #filter names													
					name = name.lower()
					namesInUnit.append(name)
			return namesInUnit

		import itertools # creating edges from a list, we got that code from our teacher as well
		def edges(edgesList, edgesDic):
			edges = list(itertools.combinations(edgesList, 2))
			for e in edges:
				key = "\t".join(sorted(list(e))) # A > B (sorted alphabetically, to avoid cases of B > A)
				updateDic(edgesDic, key)	

		lof = os.listdir(source)
		lof.sort()

		for file in lof:
			with open(source + "/" + file, "r", encoding="utf8") as f1:
				text = f1.read()
					
				split = re.split('<div3', text) # split the text into units
				for unit in split[1:]:
					unit = "<div3" + unit # restore the integrity of units		
					# print(unit) #testing
					
					namesList = taggedNames(unit) # set value		
					edges(namesList, edgesDic) #create edges from nameslist
					
		# print(edgesDic) #testing

		with open(target+"/"+"result.tsv", "w", encoding="utf8") as resultFile:
			resultFile.write("source\ttarget\tweight\n")
			for edge in edgesDic: # separate key, value with tabs
				entry = edge+"\t"+str(edgesDic[edge])+"\n"
				resultFile.write(entry)


```

Unfortunately, the number of names was too much for my netbook to handle, so I couldn't finish the social network analysis in gephi. It worked, anyway, for the toponyms I extracted with the same code.

The code for it looks as follows:


```

		import re, os

		source = ".//files"
		target = ".//res"

		#create a dictionary to save the extracted information to
		edgesDic = {} # dictionary for edges
		edgesList = [] # list for toponyms

		def updateDic(dic, key): # updating dictionary
			if key in dic:
				dic[key] += 1
			else:
				dic[key] = 1
			
		def taggedToponyms(unitText): # define function to collect tagged toponyms in edgesList
			toponymsInUnit = [] #create list for toponyms in unit
			for toponyms in re.findall(r'<placeName([^<]+)', unitText, flags=0):
				if 'tgn,':
					match = re.search(r'reg="([\w,]+)"', toponyms)
					if match:
						toponym = match.group(1) #filter toponyms													
						toponym = toponym.lower()
						toponymsInUnit.append(toponym)
			return toponymsInUnit

		import itertools # creating edges from a list
		def edges(edgesList, edgesDic):
			edges = list(itertools.combinations(edgesList, 2))
			for e in edges:
				key = "\t".join(sorted(list(e))) # A > B (sorted alphabetically, to avoid cases of B > A)
				updateDic(edgesDic, key)	

		lof = os.listdir(source)
		lof.sort()

		for file in lof:
			with open(source + "/" + file, "r", encoding="utf8") as f1:
				text = f1.read()
					
				split = re.split('<div3', text) # split the text into units
				for unit in split[1:]:
					unit = "<div3" + unit # restore the integrity of units		
					# print(unit) #testing
					
					toponymsList = taggedToponyms(unit) # set value		
					edges(toponymsList, edgesDic) #create edges from toponymsList
					
		# print(edgesDic) #testing

		with open(target+"/"+"result_topo.tsv", "w", encoding="utf8") as resultFile:
			resultFile.write("source\ttarget\tweight\n") #insert title line to final file
			for edge in edgesDic: # separate key, value with tabs in final file
				entry = edge+"\t"+str(edgesDic[edge])+"\n"
				resultFile.write(entry)

```

I only needed to alter the regular expressions.
With the result of this, the social network analysis worked. Here's a peak:

![topoSNA](/assets/img/sna.png)